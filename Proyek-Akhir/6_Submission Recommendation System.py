# -*- coding: utf-8 -*-
"""Untitled6.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1R0Mcut56xUXtesfSAulsfQs25IEALw69

Dataset yang digunakan: https://www.kaggle.com/datasets/shubhammehta21/movie-lens-small-latest-dataset

Dataset berisi list movie, rating, id movie pada imbd tmbd, dan tag

#### Mengunduh Dataset yang Digunakan
"""

! pip install kaggle

from google.colab import files

uploaded = files.upload()

for fn in uploaded.keys():
  print('User uploaded file "{name}" with length {length} bytes'.format(
      name=fn, length=len(uploaded[fn])))
  
# Then move kaggle.json into the folder where the API expects to find it.
!mkdir -p ~/.kaggle/ && mv kaggle.json ~/.kaggle/ && chmod 600 ~/.kaggle/kaggle.json

! kaggle datasets download -d shubhammehta21/movie-lens-small-latest-dataset

! unzip /content/movie-lens-small-latest-dataset.zip

"""#### Import Library yang Dibutuhkan"""

import pandas as pd
import numpy as np 
from zipfile import ZipFile
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
from pathlib import Path
import matplotlib.pyplot as plt
import plotly.express as px

"""#### Import Data dan Melakukan EDA"""

movies = pd.read_csv('movies.csv')
ratings = pd.read_csv('ratings.csv')

movies.info()

"""Memisahkan data pada fitur genre karena satu data memiliki banyak genre"""

movies['genres'] = pd.DataFrame(movies['genres'].str.replace('|', ',', regex=True))

"""Memasukkan data dengan genre yang sudah terpisah satu-satu kedalam variabel baru"""

genres_data = (movies.set_index(movies.columns.drop('genres',1).tolist())['genres']
               .str.split(',', expand=True)
               .stack()
               .reset_index()
               .rename(columns={0:'genres'})
               .loc[:, movies.columns]
               )

"""Menampilkan visualisasi banyaknya genre dalam dataset"""

fig = px.pie(genres_data, names = "genres",
             title = "<b>Counts in Genres</b>",             
             color_discrete_sequence=px.colors.sequential.Blackbody_r,             
             hole = 0.5)

fig.update_layout(title_x = 0.5,
                  title_font = dict(size = 20))

fig.update_traces(textposition='inside',
                  textinfo='percent+label',    
                  textfont_size=15,                  
                  marker=dict(line=dict(color='#000000', width = 1.5)))


fig.show()

ratings.info()

"""#### Preprocessing
Mengecek nilai null pada tiap data
"""

movies.isnull().sum()

ratings.isnull().sum()

"""Menghilangkan duplikasi judul yang ada pada film"""

# Drop duplicate of movie

movies = movies.drop_duplicates('title')
len(movies)

"""#### Content Based Filtering"""

data = movies
data.sample(5)

"""Mengambil fitur genre menggunakan tfidfvectorizer"""

from sklearn.feature_extraction.text import TfidfVectorizer
 
tf = TfidfVectorizer()
tf.fit(data['genres']) 
tf.get_feature_names()

"""Melakukan fit yang ditransformasi ke dalam bentuk matrix"""

tfidf_matrix = tf.fit_transform(data['genres']) 

tfidf_matrix.shape

"""Mengubah vektor tfidf kedalam bentuk matriks"""

tfidf_matrix.todense()

"""Menampilkan film dengan genrenya"""

pd.DataFrame(
    tfidf_matrix.todense(), 
    columns=tf.get_feature_names(),
    index=data.title
).sample(22, axis=1).sample(10, axis=0)

"""Menghitung cosine similarity pada matrix tf-idf"""

from sklearn.metrics.pairwise import cosine_similarity

cosine_sim = cosine_similarity(tfidf_matrix) 
cosine_sim

"""Membuat dataframe cosine_sim dengan baris dan kolom berupa judul film serta melihat kesamaan data pada tiap film"""

cosine_sim_df = pd.DataFrame(cosine_sim, index=data['title'], columns=data['title'])
print('Shape:', cosine_sim_df.shape)
 
cosine_sim_df.sample(5, axis=1).sample(10, axis=0)

"""Membuat fungsi movie_recommendations"""

def movie_recommendations(movie_title, similarity_data=cosine_sim_df, items=data[['title', 'genres']], k=5):
    index = similarity_data.loc[:,movie_title].to_numpy().argpartition(
        range(-1, -k, -1))
    closest = similarity_data.columns[index[-1:-(k+2):-1]]
    closest = closest.drop(movie_title, errors='ignore')
    return pd.DataFrame(closest).merge(items).head(k)

"""Membuat fungsi untuk memvisualisasikan data rekomendasi ke dalam bentuk tabel"""

def render_predict_table(data, col_width=7.0, row_height=0.5, font_size=12,
                     header_color='#40466e', row_colors=['#f1f1f2', 'w'], edge_color='w',
                     bbox=[0, 0, 1, 1], header_columns=0,
                     ax=None, **kwargs):
    if ax is None:
        size = (np.array(data.shape[::-1]) + np.array([0, 1])) * np.array([col_width, row_height])
        fig, ax = plt.subplots(figsize=size)
        ax.axis('off')
    predict_table = ax.table(cellText=data.values, bbox=bbox, colLabels=data.columns, **kwargs)
    predict_table.auto_set_font_size(False)
    predict_table.set_fontsize(font_size)

    for k, cell in predict_table._cells.items():
        cell.set_edgecolor(edge_color)
        if k[0] == 0 or k[1] < header_columns:
            cell.set_text_props(weight='bold', color='w')
            cell.set_facecolor(header_color)
        else:
            cell.set_facecolor(row_colors[k[0]%len(row_colors) ])
    return ax.get_figure(), ax

data[data.title.eq('Jungle Book, The (1967)')]

"""Hasil Prediksi"""

movie_recommendations('Jungle Book, The (1967)')

fig,ax = render_predict_table(pd.DataFrame(movie_recommendations('Jungle Book, The (1967)')), header_columns=0, col_width=7)
fig.savefig("table_predict.png")

data[data.title.eq('Alvin and the Chipmunks: The Squeakquel (2009)')]

movie_recommendations('Alvin and the Chipmunks: The Squeakquel (2009)')

fig,ax = render_predict_table(pd.DataFrame(movie_recommendations('Alvin and the Chipmunks: The Squeakquel (2009)')), header_columns=0, col_width=7)
fig.savefig("table_predict.png")

data[data.title.eq('Conjuring, The (2013)')]

movie_recommendations('Conjuring, The (2013)')

fig,ax = render_predict_table(pd.DataFrame(movie_recommendations('Conjuring, The (2013)')), header_columns=0, col_width=7)
fig.savefig("table_predict.png")

"""#### Collaborative Filtering"""

df = ratings
df

"""Encoding data user"""

user_ids = df['userId'].unique().tolist()
user_to_user_encoded = {x: i for i, x in enumerate(user_ids)}
user_encoded_to_user = {i: x for i, x in enumerate(user_ids)}

"""Encoding data movie"""

movie_ids = df['movieId'].unique().tolist()
movie_to_movie_encoded = {x: i for i, x in enumerate(movie_ids)}
movie_encoded_to_movie = {i: x for i, x in enumerate(movie_ids)}

"""Mapping data user dan movie"""

df['user'] = df['userId'].map(user_to_user_encoded)
df['movie'] = df['movieId'].map(movie_to_movie_encoded)

df

"""Menampilkan jumlah user dan movie, serta mengubah nilai rating menjadi bentuk float"""

num_users = len(user_to_user_encoded)
print(num_users)

num_movie = len(movie_encoded_to_movie)
print(num_movie)

df['rating'] = df['rating'].values.astype(np.float32)

min_rating = min(df['rating'])
max_rating = max(df['rating'])
 
print('Number of User: {}, Number of Movie: {}, Min Rating: {}, Max Rating: {}'.format(
    num_users, num_movie, min_rating, max_rating
))

df = df.sample(frac=1, random_state=57)
df

"""Melakukan train dan test split"""

x = df[['user', 'movie']].values
y = df['rating'].apply(lambda x: (x - min_rating) / (max_rating - min_rating)).values

train_indices = int(0.8 * df.shape[0])
x_train, x_val, y_train, y_val = (
    x[:train_indices],
    x[train_indices:],
    y[:train_indices],
    y[train_indices:]
)
 
print(x, y)

"""Membuat class RecommenderNet"""

import tensorflow as tf

class RecommenderNet(tf.keras.Model):
  # Insialisasi fungsi
  def __init__(self, num_users, num_movie, embedding_size, **kwargs):
    super(RecommenderNet, self).__init__(**kwargs)
    self.num_users = num_users
    self.num_movie = num_movie
    self.embedding_size = embedding_size
    self.user_embedding = layers.Embedding( #layer embedding user
        num_users,
        embedding_size,
        embeddings_initializer = 'he_normal',
        embeddings_regularizer = keras.regularizers.l2(1e-6)
    )

    self.user_bias = layers.Embedding(num_users, 1) # layer embedding user bias
    self.movie_embedding = layers.Embedding( # layer embeddings movie
        num_movie,
        embedding_size,
        embeddings_initializer = 'he_normal',
        embeddings_regularizer = keras.regularizers.l2(1e-6)
    )
    self.movie_bias = layers.Embedding(num_movie, 1) # layer embedding movie bias

  def call(self, inputs):
    user_vector = self.user_embedding(inputs[:,0])
    user_bias = self.user_bias(inputs[:, 0])
    movie_vector = self.movie_embedding(inputs[:, 1])
    movie_bias = self.movie_bias(inputs[:, 1])
 
    dot_user_movie = tf.tensordot(user_vector, movie_vector, 2) 
 
    x = dot_user_movie + user_bias + movie_bias
    
    return tf.nn.sigmoid(x) # activation sigmoid

"""Inisialisasi model dan melakukan compile"""

model = RecommenderNet(num_users, num_movie, 50)

model.compile(
    loss = tf.keras.losses.BinaryCrossentropy(),
    optimizer = keras.optimizers.Adam(learning_rate=0.0001),
    metrics=[tf.keras.metrics.RootMeanSquaredError()]
)

history = model.fit(
    x = x_train,
    y = y_train,
    batch_size = 32,
    epochs = 25,
    validation_data = (x_val, y_val)
)

"""Plotting hasil RMSE data train dan test"""

plt.plot(history.history['root_mean_squared_error'])
plt.plot(history.history['val_root_mean_squared_error'])
plt.title('model_metrics')
plt.ylabel('root_mean_squared_error')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='upper left')
plt.show()

"""Mengambil sampel untuk dilakukan prediksi film rekomendasi"""

movie_df = movies
df = pd.read_csv('ratings.csv')

user_id = df.userId.sample(5).iloc[0]
movie_watched_by_user = df[df.userId == user_id]
 
movie_not_watched = movie_df[~movie_df['movieId'].isin(movie_watched_by_user.movieId.values)]['movieId'] 
movie_not_watched = list(
    set(movie_not_watched)
    .intersection(set(movie_to_movie_encoded.keys()))
)

movie_not_watched = [[movie_to_movie_encoded.get(x)] for x in movie_not_watched]
user_encoder = user_to_user_encoded.get(user_id)
user_movie_array = np.hstack(
    ([[user_encoder]] * len(movie_not_watched), movie_not_watched)
)

"""Menampilkan hasil dari sistem rekomendasi dengan teknik *collaborative filtering*"""

ratings = model.predict(user_movie_array).flatten()
 
top_ratings_indices = ratings.argsort()[-5:][::-1]
recommended_movie_ids = [
    movie_encoded_to_movie.get(movie_not_watched[x][0]) for x in top_ratings_indices
]

print('---' * 9)
print('Movie with high ratings from users: {}'.format(user_id))
print('---' * 9)
 
top_movie_user = (
    movie_watched_by_user.sort_values(
        by = 'rating',
        ascending=False
    )
    .head(5)
    .movieId.values
)
 
movie_df_rows = movie_df[movie_df['movieId'].isin(top_movie_user)]
for row in movie_df_rows.itertuples():
    print(row.title, ':', row.genres)
 
print('----' * 8)
print('Top 5 movie recommendation for users: {} '.format(user_id))
print('----' * 8)
 
recommended_movie = movie_df[movie_df['movieId'].isin(recommended_movie_ids)]
for row in recommended_movie.itertuples():
    print(row.title, ':', row.genres)
